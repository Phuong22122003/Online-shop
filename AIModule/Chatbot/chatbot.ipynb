{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in d:\\app\\python\\lib\\site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in d:\\app\\python\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\app\\python\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\app\\python\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\app\\python\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\app\\python\\lib\\site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in d:\\app\\python\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\app\\python\\lib\\site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\app\\python\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\app\\python\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in d:\\app\\python\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\app\\python\\lib\\site-packages (from requests->transformers) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\app\\python\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\app\\python\\lib\\site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\app\\python\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/10.0 MB 1.9 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 1.8/10.0 MB 3.0 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.4/10.0 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.0/10.0 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.7/10.0 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 7.3 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.5-cp311-none-win_amd64.whl (285 kB)\n",
      "Downloading tokenizers-0.20.3-cp311-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------  2.4/2.4 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 9.7 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, tokenizers, transformers\n",
      "Successfully installed safetensors-0.4.5 tokenizers-0.20.3 transformers-4.46.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\app\\Python\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "d:\\app\\Python\\Lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "d:\\app\\Python\\Lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('D:\\WorkSpace\\Source\\webbanhang\\AIModule\\FineturingModel\\V2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('D:\\WorkSpace\\Source\\webbanhang\\AIModule\\FineturingModel\\V2')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_sentences_with_patterns(text):\n",
    "    # Các regex để phát hiện email, số điện thoại, và URL\n",
    "    email_pattern = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b\"\n",
    "    phone_pattern = r'(\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4}|\\d{4}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{3})'\n",
    "    url_pattern = r\"\\b(?:https?://|www\\.)\\S+\\b\"\n",
    "    \n",
    "    # Tách văn bản thành các câu\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    \n",
    "    # Giữ lại các câu không khớp với bất kỳ mẫu nào\n",
    "    filtered_sentences = [\n",
    "        sentence for sentence in sentences\n",
    "        if not (re.search(email_pattern, sentence) or \n",
    "                re.search(phone_pattern, sentence) or \n",
    "                re.search(url_pattern, sentence))\n",
    "    ]\n",
    "    print(filtered_sentences)\n",
    "    # Gộp lại thành văn bản sau khi lọc\n",
    "    return ' '.join(filtered_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nHỏi: chào bạn Trả lời: Chào bạn, bạn có thể tham khảo một số mẫu thiết kế biệt thự đẹp mà chúng tôi gợi ý dưới đây.', 'Thiện,56568, viber, zalo, facebook)\\nĐáp: Cảm ơn bạn.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nHỏi: chào bạn Trả lời: Chào bạn, bạn có thể tham khảo một số mẫu thiết kế biệt thự đẹp mà chúng tôi gợi ý dưới đây. Thiện,56568, viber, zalo, facebook)\\nĐáp: Cảm ơn bạn.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_sentences_with_patterns('''\n",
    "Hỏi: chào bạn Trả lời: Chào bạn, bạn có thể tham khảo một số mẫu thiết kế biệt thự đẹp mà chúng tôi gợi ý dưới đây. (Zalo, Viber): 0909.599.490 (Mr. Thiện,56568, viber, zalo, facebook)\n",
    "Đáp: Cảm ơn bạn.\n",
    "['Hỏi: chào bạn Trả lời: Chào bạn, bạn có thể tham khảo một số mẫu thiết kế biệt thự đẹp mà chúng tôi gợi ý dưới đây.', '(Zalo, Viber): 0909.599.490 (Mr.', 'Thiện, 0918.248.278, viber, zalo, facebook)\\nĐáp: Cảm ơn bạn']''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text 1:\n",
      "Hỏi: Mua quà gì cho con gái tôi mặc là đẹp đây? Trả lời: Bạn có thể chọn một bộ đầm hoặc một chiếc váy dài để tạo sự thoải mái cho bé. Một chiếc áo sơ mi hoặc áo khoác nhẹ sẽ giúp bé dễ dàng di chuyển.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = 'Mua quà gì cho con gái tôi mặc là đẹp đây?';\n",
    "input_text = f\"Hỏi: {text} Trả lời:\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "outputs = model.generate(\n",
    "    inputs['input_ids'],\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    do_sample=True,\n",
    "    max_length=64,\n",
    "    min_length=10,\n",
    "    top_k=40,\n",
    "    num_beams=5,\n",
    "    early_stopping=True,\n",
    "    no_repeat_ngram_size=2,\n",
    "    num_return_sequences=1\n",
    ")\n",
    "\n",
    "\n",
    "generated_texts = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "for i, text in enumerate(generated_texts):\n",
    "    text = text.split('|')[0]\n",
    "    text = text.split('.')\n",
    "    text = text[:2]\n",
    "    text = [t for t in text if 'http' not in t]\n",
    "    text = '.'.join(text)\n",
    "    print(f\"Generated Text {i+1}:\\n{text}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
